{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126c9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fco2models.models import UNet2DModelWrapper, Unet2DClassifierFreeModel\n",
    "from fco2models.ueval import load_models\n",
    "model_info = {\n",
    "    'cfree_100': ['../models/newds/', 'e_200.pt', UNet2DModelWrapper ]#lambda **model_params: Unet2DClassifierFreeModel(model_params, keep_channels=[0, 1, 2, 13], num_channels=14)],\n",
    "}\n",
    "models = load_models(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d21b380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute these values for all models\n",
    "from fco2models.ueval import print_loss_info\n",
    "for key in models.keys():\n",
    "    print(f'loading {key}')\n",
    "    print_loss_info(models[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fco2models.utraining import prep_df, make_monthly_split, get_segments_random, get_segments, get_context_mask, normalize_dss, get_stats_df\n",
    "DATA_PATH = \"../data/training_data/\"\n",
    "df = pd.read_parquet(DATA_PATH + \"SOCAT_1982_2021_grouped_colloc_augm_bin.pq\", engine='pyarrow')\n",
    "df = prep_df(df, bound=True, add_clim=False, add_seas=False)[0]\n",
    "# df['sst_clim'] += 273.15\n",
    "# df['sst_anom'] = df['sst_cci'] - df['sst_clim']\n",
    "# df['sss_anom'] = df['sss_cci'] - df['sss_clim']\n",
    "# df['chl_anom'] = df['chl_globcolour'] - df['chl_clim']\n",
    "# df['ssh_anom'] = df['ssh_sla'] - df['ssh_clim']\n",
    "# df['mld_anom'] = df['mld_dens_soda'] - df['mld_clim']\n",
    "#map expocode column to int\n",
    "expocode_map = df['expocode'].unique()\n",
    "expocode_map = {expocode: i for i, expocode in enumerate(expocode_map)}\n",
    "df['expocode_id'] = df['expocode'].map(expocode_map) \n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb934f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "expocodes = df['expocode_id'].unique()\n",
    "print(f\"number of unique expocodes: {len(expocodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc72b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expocode = expocode_map[\"AG5W20141113\"]#expocodes[1000]\n",
    "print(f'Expocode ID: {expocode}')\n",
    "cruise = df[df['expocode_id'] == expocode]\n",
    "print(f'Cruise shape: {cruise.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6870af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = models['cfree_100']\n",
    "predictors = model_info['params']['predictors']\n",
    "target = 'fco2rec_uatm'\n",
    "info = 'window_id'\n",
    "cols = [target] + predictors + [info]\n",
    "cruise_ds = get_segments(cruise, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f0c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fco2models.utraining import normalize_dss\n",
    "params = model_info['params']\n",
    "stats = {\n",
    "    'means': params['train_means'],\n",
    "    'stds': params['train_stds'],\n",
    "    'mins': params['train_mins'],\n",
    "    'maxs': params['train_maxs'],\n",
    "}\n",
    "window_ids = cruise_ds[:, -1:, :].astype(int)\n",
    "cruise_ds = normalize_dss([cruise_ds[:, :-1, :]], stats, params['mode'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1259c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fco2models.utraining import full_denoise\n",
    "from fco2models.ueval import rescale\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusers import DDIMScheduler\n",
    "\n",
    "n_rec = 50\n",
    "context_ds = np.repeat(cruise_ds[:, 1:, :], n_rec, axis=0)\n",
    "context_ds = torch.from_numpy(context_ds).float()\n",
    "target_ds = cruise_ds[:, 0, :]\n",
    "\n",
    "#model_info['model'].set_w(1)\n",
    "loader = DataLoader(context_ds, batch_size=128, shuffle=False)\n",
    "scheduler = DDIMScheduler(num_train_timesteps=model_info['noise_scheduler'].config.num_train_timesteps,\n",
    "                          beta_schedule=model_info['noise_scheduler'].config.beta_schedule,\n",
    "                          clip_sample_range=model_info['noise_scheduler'].config.clip_sample_range,\n",
    "                          )\n",
    "scheduler.set_timesteps(50)\n",
    "samples_norm = full_denoise(model_info['model'], scheduler, loader, jump=None)\n",
    "samples = rescale(samples_norm.copy(), params, params['mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052975ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def samples_to_df(samples, index):\n",
    "    samples_index = np.concatenate((samples, index), axis=1)\n",
    "    # print(samples_index.shape)\n",
    "    n_samples, n_cols, n_bins = samples_index.shape\n",
    "    samples_index_flat = np.full((n_samples*n_bins, n_cols), np.nan)\n",
    "    for i in range(samples_index.shape[1]):\n",
    "        samples_index_flat[:, i] = samples_index[:, i, :].flatten()\n",
    "    df = pd.DataFrame(samples_index_flat, columns=[f\"sample_{i}\" for i in range(n_rec)] + ['window_id'])\n",
    "    df['window_id'] = df['window_id'].astype(int)\n",
    "    df.set_index(['window_id'], inplace=True)\n",
    "    return df\n",
    "\n",
    "res_df = samples_to_df(samples.reshape(-1, n_rec, 64), window_ids)\n",
    "pred_columns = res_df.columns[:-1]\n",
    "res_df['mean_pred'] = res_df[pred_columns].mean(axis=1)\n",
    "res_df['std_pred'] = res_df[pred_columns].std(axis=1)\n",
    "\n",
    "cruise.set_index(['window_id'], inplace=True)\n",
    "cruise = pd.concat([cruise, res_df], axis=1)\n",
    "cruise.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ad514",
   "metadata": {},
   "outputs": [],
   "source": [
    "cruise.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def plot_line_comparison(ax, y, yhat, **kwargs):\n",
    "    from scipy.stats import pearsonr\n",
    "\n",
    "    y.plot(ax=ax, **(kwargs | dict(label='SOCAT')),)\n",
    "    yhat.plot(ax=ax, **kwargs)\n",
    "    \n",
    "    m = y.notnull() & yhat.notnull()\n",
    "    y = y[m]\n",
    "    yhat = yhat[m]\n",
    "    \n",
    "    metric_txt = (\n",
    "        f\"r2 = {metrics.r2_score(y, yhat):.2f}\"\n",
    "        f\"\\nRMSE = {metrics.root_mean_squared_error(y, yhat):.1f}\"\n",
    "        f\"\\nBias = {(yhat - y).mean():.1f}\"\n",
    "        f\"\\nPearson R = {pearsonr(y, yhat)[0]:.2f}\")\n",
    "    \n",
    "    ax.text(0.01, 0.04, metric_txt, transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='bottom')\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_xticks(np.arange(0, int(y.index.max()), 64))\n",
    "    \n",
    "\n",
    "def plot_diff_samples(ax, recs, truth, **kwargs):\n",
    "    windows = recs.index.get_level_values('window_id')\n",
    "    recs = recs.values.T\n",
    "    mean_pred = recs.mean(axis=0)\n",
    "    uncert = recs.std(axis=0)\n",
    "    ax.plot(windows, truth, **kwargs)\n",
    "    ax.plot(windows, mean_pred, **kwargs)\n",
    "    ax.fill_between(windows, mean_pred-uncert, mean_pred+uncert, alpha=0.2, color='k')\n",
    "\n",
    "def plot_all_samples(ax, recs, truth, **kwargs):\n",
    "    windows = recs.index.get_level_values('window_id')\n",
    "    recs = recs.values.T\n",
    "    ax.plot(windows, truth, **kwargs)\n",
    "    ax.plot(windows, recs.T, **kwargs, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cruise.set_index(['window_id'], inplace=True)\n",
    "fig, axs = plt.subplots(3, 1, figsize=(20, 5), sharex=True, sharey=True)\n",
    "plot_line_comparison(axs[0], cruise['fco2rec_uatm'], cruise['mean_pred'], label='Predictions')\n",
    "axs[0].set_title(f\"Expocode: {expocode}\")\n",
    "axs[0].grid(True, axis='x')\n",
    "axs[0].set_ylim(-60, 80)\n",
    "plot_diff_samples(axs[1],cruise[pred_columns], cruise['fco2rec_uatm'], label='Predictions')\n",
    "axs[1].grid(True, axis='x')\n",
    "plot_all_samples(axs[2], cruise[pred_columns], cruise['fco2rec_uatm'], label='Predictions')\n",
    "cruise.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb9582",
   "metadata": {},
   "source": [
    "with random shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cruise.drop(columns=pred_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = models['cfree_100']\n",
    "params = model_info['params']\n",
    "predictors = model_info['params']['predictors']\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a7c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion_step(model, noise_scheduler, x, t, jump):\n",
    "    # Get model pred\n",
    "    sample = x[:, 0:1, :]  # Assuming the first channel is the sample\n",
    "    with torch.no_grad():\n",
    "        residual = model(x, t, return_dict=False)[0]\n",
    "    output_scheduler = noise_scheduler.step(residual, t, sample)\n",
    "    if jump is not None:\n",
    "        x_0 = output_scheduler.pred_original_sample\n",
    "        if t < jump:\n",
    "            sample = x_0\n",
    "            # sample = output_scheduler.prev_sample\n",
    "        else:\n",
    "            sample = noise_scheduler.add_noise(x_0, torch.randn_like(sample), t - jump)\n",
    "    else:\n",
    "        # Update sample with step\n",
    "        sample = output_scheduler.prev_sample\n",
    "    return sample\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from fco2models.ueval import rescale\n",
    "def multidiffusion_denoise(model, noise_scheduler, sample_context, overlap_fun, jump=20, n_rec=5):\n",
    "    \"\"\"full denoising loop for diffusion model\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training on {device}\")\n",
    "    model.to(device)\n",
    "\n",
    "    sample_shape = (n_rec, sample_context.shape[0])\n",
    "    sample_context = np.stack([sample_context] * n_rec, axis=0)  # Repeat context for n_rec\n",
    "    sample_context[:, :, 0] = np.random.randn(*sample_shape)  # Initialize the first channel with random values\n",
    "    step = 0\n",
    "    all_samples = [sample_context[:, :, 0].copy()]\n",
    "\n",
    "    t_loop = noise_scheduler.timesteps[::jump]\n",
    "    #t_full = torch.arange(jump-1, -1, -1)\n",
    "    #t_loop = torch.cat([t_loop, t_full], dim=0)  # Concatenate the timesteps for the loop\n",
    "    print(f\"Timesteps for inference: {t_loop}\")\n",
    "\n",
    "    for t in tqdm(t_loop, desc=f\"Inference\"):\n",
    "        sample_context_overlap, windows_overlap = overlap_fun(sample_context, step, n_rec=n_rec)\n",
    "        sample_context_overlap = torch.from_numpy(sample_context_overlap).float().to(device)\n",
    "        loader = DataLoader(sample_context_overlap, batch_size=128, shuffle=False)\n",
    "        samples = []\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            sample = diffusion_step(model, noise_scheduler, batch, t, jump)\n",
    "            samples.append(sample.cpu().numpy())\n",
    "\n",
    "        samples = np.concatenate(samples, axis=0).reshape(n_rec, -1)\n",
    "        sample = np.zeros(sample_shape, dtype=np.float32)\n",
    "        weights = np.zeros(sample_shape, dtype=np.float32)\n",
    "\n",
    "\n",
    "        for rec in range(samples.shape[0]):\n",
    "            for i in range(samples.shape[1]):\n",
    "                sample[rec, windows_overlap[rec, i]] += samples[rec, i]\n",
    "                weights[rec, windows_overlap[rec, i]] += 1\n",
    "        \n",
    "        #replace zero weights with nans\n",
    "        weights[weights == 0] = np.nan\n",
    "        sample /= weights\n",
    "        # if (jump is not None) and t - jump > 0:\n",
    "        sample[np.isnan(sample)] = sample_context[np.isnan(sample), 0]\n",
    "\n",
    "        sample_context[:, :, 0] = sample  # Update the context with the new sample\n",
    "        all_samples.append(sample_context[:, :, 0].copy())\n",
    "        step += 1\n",
    "\n",
    "    return sample_context, np.array(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65d7116",
   "metadata": {},
   "outputs": [],
   "source": [
    "cruise_array = cruise[predictors].values\n",
    "window_ids = cruise['window_id'].values\n",
    "padded_cruise_array = np.pad(cruise_array, ((64, 64), (0, 0)), mode='symmetric')\n",
    "cruise_array.shape, padded_cruise_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b635f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifting_fun(sample_context, step, n_rec, segment_len=64):\n",
    "    # sample_context is expected to be of shape (n_rec, n_samples, n_features)\n",
    "    windows = np.arange(sample_context.shape[1])\n",
    "    ds = []\n",
    "    ds_windows = []\n",
    "    for rec in range(n_rec):\n",
    "        offset = np.random.randint(-20,20)\n",
    "        # if step>=45:\n",
    "        #     print(f\"Processing record {rec}, offset: {offset}\")\n",
    "        #print(f\"Processing record {rec}, offset: {offset}\")\n",
    "        sample_context_rec = sample_context[rec, segment_len + offset:-segment_len + offset:, :]\n",
    "        windows_rec = windows[segment_len + offset:-segment_len + offset]\n",
    "\n",
    "        n_segments = sample_context_rec.shape[0] // segment_len # this should be constant anyway but whatever\n",
    "        n_c = sample_context_rec.shape[1] # this too\n",
    "        ds_rec = np.zeros((n_segments, n_c, segment_len), dtype=np.float32)\n",
    "        for c in range(sample_context_rec.shape[1]):\n",
    "            ds_rec[:, c, :] = sample_context_rec[:n_segments*segment_len, c].reshape(n_segments, segment_len)\n",
    "        windows_rec = windows_rec[:n_segments*segment_len]\n",
    "        ds.append(ds_rec)\n",
    "        ds_windows.append(windows_rec)\n",
    "\n",
    "    ds = np.concatenate(ds, axis=0)\n",
    "    ds_windows = np.concatenate(ds_windows, axis=0)\n",
    "    ds_windows = ds_windows.reshape(n_rec, -1)\n",
    "\n",
    "    return ds, ds_windows\n",
    "\n",
    "def md_fun(sample_context, _, n_rec, segment_len=64):\n",
    "    # sample_context is expected to be of shape (n_rec, n_samples, n_features)\n",
    "    windows = np.arange(sample_context.shape[1])\n",
    "    ds = []\n",
    "    ds_windows = []\n",
    "    for rec in range(n_rec):\n",
    "        for step in range(0, sample_context.shape[1] - segment_len + 1, segment_len - 15):\n",
    "            ds_step = sample_context[rec, step:step + segment_len, :]\n",
    "            ds.append(ds_step.swapaxes(0, 1)[np.newaxis])  # Swap axes to have (n_rec, n_features, segment_len)\n",
    "            ds_windows.append(windows[step:step + segment_len])\n",
    "    ds = np.concatenate(ds, axis=0)\n",
    "    # ds = ds.swapaxes(1, 2)  \n",
    "    ds_windows = np.concatenate(ds_windows, axis=0)\n",
    "    ds_windows = ds_windows.reshape(n_rec, -1)\n",
    "    # ds_windows = np.tile(win)  # Repeat windows for n_rec\n",
    "    #print(f\"ds shape: {ds.shape}, ds_windows shape: {ds_windows.shape}\")\n",
    "\n",
    "    return ds, ds_windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d36f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDIMScheduler\n",
    "sample = np.full((padded_cruise_array.shape[0], 1), np.nan)\n",
    "#mask = np.ones_like(sample)\n",
    "sample_context = np.concatenate((sample, padded_cruise_array), axis=1)\n",
    "stats = {\n",
    "    'means': params['train_means'],\n",
    "    'stds': params['train_stds'],\n",
    "    'mins': params['train_mins'],\n",
    "    'maxs': params['train_maxs'],\n",
    "}\n",
    "sample_context = normalize_dss([sample_context[:, :, np.newaxis]], stats, params['mode'])[0]\n",
    "#sample_context[:, 0, 0] = np.random.randn(sample_context.shape[0])  # Random noise for the first channel\n",
    "sample_context = np.concatenate((sample_context, np.ones_like(sample)[:, :, np.newaxis]), axis=1) # Set the last channel to ones\n",
    "\n",
    "scheduler = DDIMScheduler(num_train_timesteps=model_info['noise_scheduler'].config.num_train_timesteps,\n",
    "                          beta_schedule=model_info['noise_scheduler'].config.beta_schedule,\n",
    "                          clip_sample_range=model_info['noise_scheduler'].config.clip_sample_range,\n",
    "                          )\n",
    "scheduler.set_timesteps(50)\n",
    "# model_info['model'].set_w(1)\n",
    "n_rec = 100\n",
    "sample, all_samples = multidiffusion_denoise(\n",
    "    model_info['model'],\n",
    "    scheduler,\n",
    "    sample_context.squeeze(axis=-1),\n",
    "    overlap_fun=shifting_fun,  \n",
    "    jump=None,\n",
    "    n_rec=n_rec\n",
    ")\n",
    "sample[:, :, 0:1] = rescale(sample[:, :, 0:1].reshape(-1, 1), params, params['mode']).reshape(n_rec, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798a7bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['predictors'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9367b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n_steps = 5\n",
    "fig, ax = plt.subplots(n_steps + 1, 1, figsize=(20, n_steps*5), sharey=True)\n",
    "offsets = [-18, 9, -1, -19, -8]\n",
    "for i in range(1, n_steps + 1):\n",
    "    s = all_samples[-i, 0, 64:-64]  # Get the sample for the current step\n",
    "    ax[i-1].plot(s, label='Sample', color='r')\n",
    "    #ax[i-1].set_ylim(-0.1, 0.2)\n",
    "    # plot running mean of the sample\n",
    "    # ax[i-1].plot(sample.rolling(10).mean(), label='Running Mean', color='b')\n",
    "    ax[i-1].set_title(f'Step {-i}')\n",
    "    ax[i-1].set_xticks(np.arange(0, int(all_samples.shape[2]), 64) + offsets[i - 1])\n",
    "    ax[i-1].grid(True, axis='x', linewidth=2)\n",
    "\n",
    "ax[n_steps].plot(all_samples[-21, 0, 64:-64], label='Final Sample', color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d686cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_columns = [f'sample_{i}' for i in range(n_rec)]\n",
    "cruise.loc[:, pred_columns] = sample[:, 64:-64, 0].T\n",
    "cruise.loc[:, 'mean_pred'] = cruise[pred_columns].mean(axis=1)\n",
    "cruise.loc[:, 'std_pred'] = cruise[pred_columns].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cruise.set_index(['window_id'], inplace=True)\n",
    "fig, axs = plt.subplots(3, 1, figsize=(20, 5), sharex=True, sharey=True)\n",
    "plot_line_comparison(axs[0], cruise['fco2rec_uatm'], cruise['mean_pred'], label='Predictions')\n",
    "axs[0].set_title(f\"Expocode: {expocode}\")\n",
    "axs[0].grid(True, axis='x')\n",
    "axs[0].set_ylim(-60, 80)\n",
    "plot_diff_samples(axs[1],cruise[pred_columns], cruise['fco2rec_uatm'], label='Predictions')\n",
    "axs[1].grid(True, axis='x')\n",
    "plot_all_samples(axs[2], cruise[pred_columns], cruise['fco2rec_uatm'], label='Predictions')\n",
    "axs[2].grid(True, axis='x')\n",
    "cruise.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcea847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75176c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oceanco2diffusion-data-exploration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
